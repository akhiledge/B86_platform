5.2 Expressing Program Performance
We need a way to express program performance that can guide us in improving the code. A useful measure
for many programs is Cycles Per Element (CPE). This measure helps us understand the loop performance of
an iterative program at a detailed level. Such a measure is appropriate for programs that perform a repetitive
computation, such as processing the pixels in an image or computing the elements in a matrix product.
The sequencing of activities by a processor is controlled by a clock providing a regular signal of some
frequency, expressed in either Megahertz (Mhz), i.e., millions of cycles per second, or Gigahertz (GHz), i.e.,
billions of cycles per second. For example, when product literature characterizes a system as a “1.4 GHz”
processor, it means that the processor clock runs at 1,400 Megahertz. The time required for each clock
cycle is given by the reciprocal of the clock frequency. These are typically expressed in nanoseconds, i.e.,
billionths of a second. A 2 GHz clock has a 0.5-nanosecond period, while a 500 Mhz clock has a period of
2 nanoseconds. From a programmer’s perspective, it is more instructive to express measurements in clock
cycles rather than nanoseconds. That way, the measurements are less dependent on the particular model of
processor being evaluated, and they help us understand exactly how the program is being executed by the
machine.
Many procedures contain a loop that iterates over a set of elements. For example, functions vsum1 and
vsum2 in Figure 5.1 both compute the sum of two vectors of length Ò . The first computes one element of
the destination vector per iteration. The second uses a technique known as loop unrolling to compute two
elements per iteration. This version will only work properly for even values of Ò . Later in this chapter we
cover loop unrolling in more detail, including how to make it work for arbitrary values of Ò .
The time required by such a procedure can be characterized as a constant plus a factor proportional to the
number of elements processed. For example, Figure 5.2 shows a plot of the number of clock cycles required
by the two functions for a range of values of Ò . Using a least squares fit, we find that the two function run
times (in clock cycles) can be approximated by lines with equations 1⁄4 · 1⁄4 Ò and ¿ · ¿ Ò , respectively.
These equations indicated an overhead of 80 to 84 cycles to initiate the procedure, set up the loop, and
complete the procedure, plus a linear factor of 3.5 or 4.0 cycles per element. For large values of Ò (say
greater than 50), the run times will be dominated by the linear factors. We refer to the coefficients in these
terms as the effective number of Cycles per Element, abbreviated “CPE.” Note that we prefer measuring
the number of cycles per element rather than the number of cycles per iteration, because techniques such as
loop unrolling allow us to use fewer iterations to complete the computation, but our ultimate concern is how
fast the procedure will run for a given vector length. We focus our efforts on minimizing the CPE for our
computations. By this measure, vsum2, with a CPE of 3.50, is superior to vsum1, with a CPE of 4.0.
